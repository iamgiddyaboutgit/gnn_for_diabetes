{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Counts on Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest Ref: 226\n",
      "GTCAATCTCCTGGGCTCCTGGGTTCCGTCTGCCCTGTTCATAGAGACAGAATGAGGGCGTCCCCAGGTGGTGAGCTCAGGGACGTGTGTGTGTGTGTGTGTGTGTGTAACCATCAATCTCCTGGGCTCCTGGGTTCCGTCTGCCCTGTTCATAGGGATGGAATGAGGGCGTCCCCAGGTGGTGAGCTCAGGGACGTTGTGTGTGTGTGTGTGTGTGTGTGTAACCA\n",
      "Longest Alt: 804\n",
      "AGTGGTACTTGGTGGTGGTGGTGGTGCTTGGTGATGGTGGTACTTGGTGGTGGTGGTGGTACTTGGTGGTGATGGTACTTGGTGGTGGTGGTACTTGGTGGTGGCAGTGGTACTTGGTGGTGGTACTTGGTGGTACTTGGTGGTGGTGGTGGTACTTGGTGGTGGCGGTGGTACTTGGTGGTGCTGGTGGTGCTTGGTGGTGGTGGTGGTACTTGGTGGTGGTGATGGTACTTGGTGGTGGTGGTGGTGGTACTTGGTGGTGGTACTTGGTGGTACTTGGTGGTGGTGGCGGTACTTGGTGGTGGTGGCGGTGGCACTTGGTGGTGGTGGTGCTTGGTGGTGGTGATGGTACTTGGTGGTGGTGATGGTACTTGGTGGTGGTGGTGGTGGTACTTGGTGGTGAGTGGTACTTGGTGGTGGTGGTGGTGCTTGGTGGTGGTGGTACTTGGTGGTGGTGGTGGTACTTGGTGGTGATGGTACTTGGTGGTGGTGGTACTTGGTGGTGGCAGTGGTACTTGGTGGTGGTACTTGGTGGTACTTGGTGGTGGTGGTGGTACTTGGTGGTGGCGGTGGTACTTGGTGGTGCTGGTGGTGCTTGGTGGTGGTGGTGGTACTTGGTGGTGGTGATGGTACTTGGTGGTGGTGGTGGTGGTACTTGGTGGTGGTACTTGGTGGTACTTGGTGGTGGTGGCGGTACTTGGTGGTGGTGGCGGTGGCACTTGGTGGTGGTGGTGCTTGGTGGTGGTGATGGTACTTGGTGGTGGTGATGGTACTTGGTGGTGGTGGTGGTGGTACTTGGTGGTG\n",
      "Most Variants: 4097\n",
      "Max Variants: 105267\n",
      "246571185\n",
      "583\n",
      "1148\n"
     ]
    }
   ],
   "source": [
    "datapath = \"./Data/variants/\"\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "\n",
    "longest_ref = 0\n",
    "longest_ref_string = \"\"\n",
    "longest_alt = 0\n",
    "longest_alt_string = \"\"\n",
    "most_variants = 0\n",
    "counter = 1\n",
    "max_variants = 0\n",
    "largest_pos = 0\n",
    "smallest_pos = 99999999999999\n",
    "largest_node = 0\n",
    "total_files = len(os.listdir(datapath))\n",
    "for filename in os.listdir(datapath):\n",
    "    # print(\"Progress: \" + str(counter) + \"/\" + str(total_files))\n",
    "    df = pd.read_table(os.path.join(datapath, filename))\n",
    "    num_variants = 0\n",
    "    curr_node = -1\n",
    "    num_variants_total = 0\n",
    "    for node, pos, ref, alt in zip(df['node_id'], df['POS'], df['REF'], df['ALT']):\n",
    "        # if node == 1140:\n",
    "        #     print(\"aaaaa\")\n",
    "        if node > largest_node:\n",
    "            largest_node = node\n",
    "        if node > curr_node:\n",
    "            num_variants = 0\n",
    "            curr_node = node\n",
    "\n",
    "        if pos > largest_pos:\n",
    "            largest_pos = pos\n",
    "        if pos < smallest_pos:\n",
    "            smallest_pos = pos\n",
    "        ref = regex.sub('', ref)\n",
    "        alt = regex.sub('', alt)\n",
    "        if len(ref) > longest_ref:\n",
    "            longest_ref = len(ref)\n",
    "            longest_ref_string = ref\n",
    "        if len(alt) > longest_alt:\n",
    "            longest_alt = len(alt)\n",
    "            longest_alt_string = alt\n",
    "\n",
    "        num_variants += 1\n",
    "        num_variants_total += 1\n",
    "        if num_variants > most_variants:\n",
    "            most_variants = num_variants\n",
    "        if num_variants_total > max_variants:\n",
    "            max_variants = num_variants_total\n",
    "    counter += 1\n",
    "\n",
    "print(\"Longest Ref: \" + str(longest_ref))\n",
    "print(longest_ref_string)\n",
    "print(\"Longest Alt: \" + str(longest_alt))\n",
    "print(longest_alt_string)\n",
    "print(\"Most Variants: \" + str(most_variants))\n",
    "print(\"Max Variants: \" + str(max_variants))\n",
    "print(largest_pos)\n",
    "print(smallest_pos)\n",
    "print(largest_node)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate 1-, 2-, and 3- mer combinations ###\n",
    "The embedding for a variant will be of size 85; the first element will be the position of the variant normalized using pytorch.normalize with default settings, the next 84 will be the number of occurences of each of the k-mer substrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "['A', 'C', 'T', 'G', 'AA', 'AC', 'AT', 'AG', 'CA', 'CC', 'CT', 'CG', 'TA', 'TC', 'TT', 'TG', 'GA', 'GC', 'GT', 'GG', 'AAA', 'AAC', 'AAT', 'AAG', 'ACA', 'ACC', 'ACT', 'ACG', 'ATA', 'ATC', 'ATT', 'ATG', 'AGA', 'AGC', 'AGT', 'AGG', 'CAA', 'CAC', 'CAT', 'CAG', 'CCA', 'CCC', 'CCT', 'CCG', 'CTA', 'CTC', 'CTT', 'CTG', 'CGA', 'CGC', 'CGT', 'CGG', 'TAA', 'TAC', 'TAT', 'TAG', 'TCA', 'TCC', 'TCT', 'TCG', 'TTA', 'TTC', 'TTT', 'TTG', 'TGA', 'TGC', 'TGT', 'TGG', 'GAA', 'GAC', 'GAT', 'GAG', 'GCA', 'GCC', 'GCT', 'GCG', 'GTA', 'GTC', 'GTT', 'GTG', 'GGA', 'GGC', 'GGT', 'GGG']\n"
     ]
    }
   ],
   "source": [
    "bases = ['A', 'C', 'T', 'G']\n",
    "k_mers = ['A', 'C', 'T', 'G']\n",
    "\n",
    "for base in bases:\n",
    "    for base2 in bases:\n",
    "        k_mers.append(base + base2)\n",
    "\n",
    "for base in bases:\n",
    "    for base2 in bases:\n",
    "        for base3 in bases:\n",
    "            k_mers.append(base + base2 + base3)\n",
    "\n",
    "print(len(k_mers))\n",
    "print(k_mers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset for GNN #"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab adjacency matrix from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 211276])\n",
      "torch.Size([211276, 1])\n"
     ]
    }
   ],
   "source": [
    "from pandas import isna\n",
    "\n",
    "datapath = \"./Data/graph_structure.tsv\"\n",
    "\n",
    "edge_idx = []\n",
    "edge_feats = []\n",
    "\n",
    "df = pd.read_table(datapath)\n",
    "for node1, node2, score in zip(df[\"node_A_num\"], df[\"node_B_num\"], df['combined_score']):\n",
    "    if not isna(node1) and not isna(node2) and not (node1 > 1148 or node2 > 1148):\n",
    "        edge_idx.append([node1, node2])\n",
    "        edge_feats.append(score)\n",
    "\n",
    "edge_idx = torch.LongTensor(edge_idx).T\n",
    "edge_feats = torch.Tensor(edge_feats).unsqueeze(1)\n",
    "print(edge_idx.shape)\n",
    "print(edge_feats.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab labels and assign them categorical integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['African Ancestry in Southwest US' 'African Caribbean in Barbados'\n",
      " 'Bengali in Bangladesh' 'British in England and Scotland'\n",
      " 'Chinese Dai in Xishuangbanna, China' 'Colombian in Medellin, Colombia'\n",
      " 'Esan in Nigeria' 'Finnish in Finland'\n",
      " 'Gambian in Western Division, The Gambia' 'Gujarati Indian in Houston,TX'\n",
      " 'Han Chinese in Bejing, China' 'Iberian populations in Spain'\n",
      " 'Indian Telugu in the UK' 'Japanese in Tokyo, Japan'\n",
      " 'Kinh in Ho Chi Minh City, Vietnam' 'Luhya in Webuye, Kenya'\n",
      " 'Mende in Sierra Leone' 'Mexican Ancestry in Los Angeles, California'\n",
      " 'Peruvian in Lima, Peru' 'Puerto Rican in Puerto Rico'\n",
      " 'Punjabi in Lahore,Pakistan' 'Southern Han Chinese, China'\n",
      " 'Sri Lankan Tamil in the UK' 'Toscani in Italy'\n",
      " 'Utah residents with Northern and Western European ancestry'\n",
      " 'Yoruba in Ibadan, Nigeria']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "datapath = \"./Data/ethnicities.tsv\"\n",
    "\n",
    "ethnicities = set()\n",
    "ethnicity_le = LabelEncoder()\n",
    "\n",
    "df = pd.read_table(datapath)\n",
    "for eth in df['population_description']:\n",
    "    ethnicities.add(eth)\n",
    "\n",
    "ethnicity_le.fit(list(ethnicities))\n",
    "print(ethnicity_le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle Successful\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./pickles/ethset.pkl', 'wb') as fp:\n",
    "    pickle.dump(ethnicities, fp)\n",
    "    print(\"Pickle Successful\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Largest values in subset of data I'm working with, grabbed from the earlier section \"Perform counts on data\"\n",
    "# Used to pad data so that everything is of uniform size\n",
    "largest_node_id = 1148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1/116\n",
      "Progress: 2/116\n",
      "Progress: 3/116\n",
      "Progress: 4/116\n",
      "Progress: 5/116\n",
      "Progress: 6/116\n",
      "Progress: 7/116\n",
      "Progress: 8/116\n",
      "Progress: 9/116\n",
      "Progress: 10/116\n",
      "Progress: 11/116\n",
      "Progress: 12/116\n",
      "Progress: 13/116\n",
      "Progress: 14/116\n",
      "Progress: 15/116\n",
      "Progress: 16/116\n",
      "Progress: 17/116\n",
      "Progress: 18/116\n",
      "Progress: 19/116\n",
      "Progress: 20/116\n",
      "Progress: 21/116\n",
      "Progress: 22/116\n",
      "Progress: 23/116\n",
      "Progress: 24/116\n",
      "Progress: 25/116\n",
      "Progress: 26/116\n",
      "Progress: 27/116\n",
      "Progress: 28/116\n",
      "Progress: 29/116\n",
      "Progress: 30/116\n",
      "Progress: 31/116\n",
      "Progress: 32/116\n",
      "Progress: 33/116\n",
      "Progress: 34/116\n",
      "Progress: 35/116\n",
      "Progress: 36/116\n",
      "Progress: 37/116\n",
      "Progress: 38/116\n",
      "Progress: 39/116\n",
      "Progress: 40/116\n",
      "Progress: 41/116\n",
      "Progress: 42/116\n",
      "Progress: 43/116\n",
      "Progress: 44/116\n",
      "Progress: 45/116\n",
      "Progress: 46/116\n",
      "Progress: 47/116\n",
      "Progress: 48/116\n",
      "Progress: 49/116\n",
      "Progress: 50/116\n",
      "Progress: 51/116\n",
      "Progress: 52/116\n",
      "Progress: 53/116\n",
      "Progress: 54/116\n",
      "Progress: 55/116\n",
      "Progress: 56/116\n",
      "Progress: 57/116\n",
      "Progress: 58/116\n",
      "Progress: 59/116\n",
      "Progress: 60/116\n",
      "Progress: 61/116\n",
      "Progress: 62/116\n",
      "Progress: 63/116\n",
      "Progress: 64/116\n",
      "Progress: 65/116\n",
      "Progress: 66/116\n",
      "Progress: 67/116\n",
      "Progress: 68/116\n",
      "Progress: 69/116\n",
      "Progress: 70/116\n",
      "Progress: 71/116\n",
      "Progress: 72/116\n",
      "Progress: 73/116\n",
      "Progress: 74/116\n",
      "Progress: 75/116\n",
      "Progress: 76/116\n",
      "Progress: 77/116\n",
      "Progress: 78/116\n",
      "Progress: 79/116\n",
      "Progress: 80/116\n",
      "Progress: 81/116\n",
      "Progress: 82/116\n",
      "Progress: 83/116\n",
      "Progress: 84/116\n",
      "Progress: 85/116\n",
      "Progress: 86/116\n",
      "Progress: 87/116\n",
      "Progress: 88/116\n",
      "Progress: 89/116\n",
      "Progress: 90/116\n",
      "Progress: 91/116\n",
      "Progress: 92/116\n",
      "Progress: 93/116\n",
      "Progress: 94/116\n",
      "Progress: 95/116\n",
      "Progress: 96/116\n",
      "Progress: 97/116\n",
      "Progress: 98/116\n",
      "Progress: 99/116\n",
      "Progress: 100/116\n",
      "Progress: 101/116\n",
      "Progress: 102/116\n",
      "Progress: 103/116\n",
      "Progress: 104/116\n",
      "Progress: 105/116\n",
      "Progress: 106/116\n",
      "Progress: 107/116\n",
      "Progress: 108/116\n",
      "Progress: 109/116\n",
      "Progress: 110/116\n",
      "Progress: 111/116\n",
      "Progress: 112/116\n",
      "Progress: 113/116\n",
      "Progress: 114/116\n",
      "Progress: 115/116\n",
      "Progress: 116/116\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "import os\n",
    "\n",
    "datapath = \"./Data/variants/\"\n",
    "datapath_labels = \"./Data/ethnicities.tsv\"\n",
    "# This data_list will be used to create our dataset\n",
    "data_list = []\n",
    "\n",
    "counter = 1\n",
    "total_files = len(os.listdir(datapath))\n",
    "idx = 0\n",
    "for filename in os.listdir(datapath):\n",
    "    print(\"Progress: \" + str(counter) + \"/\" + str(total_files))\n",
    "\n",
    "    # Create the features for each node\n",
    "    df = pd.read_table(os.path.join(datapath, filename))\n",
    "    node_feats = []\n",
    "    for i in range(largest_node_id + 1):\n",
    "        curr_node_feats = np.zeros(84)\n",
    "        node_id_list = df[df[\"node_id\"] == i]\n",
    "        if len(node_id_list) != 0:\n",
    "            for alt in node_id_list[\"ALT\"]:\n",
    "                for i, kmer in enumerate(k_mers):\n",
    "                    curr_node_feats[i] += alt.count(kmer)\n",
    "            \n",
    "        node_feats.append(curr_node_feats)  \n",
    "\n",
    "    node_feats = torch.from_numpy(np.array(node_feats))\n",
    "    # print(node_feats.shape)\n",
    "\n",
    "\n",
    "    # Get label for this file\n",
    "    id = filename.split(\".\")[0]\n",
    "    df = pd.read_table(datapath_labels)\n",
    "    label_entry = df[df[\"sample_id\"] == id]\n",
    "    if len(label_entry) == 0:\n",
    "        print(\"ERROR\")\n",
    "        print(id)\n",
    "    \n",
    "    label_int = ethnicity_le.transform(label_entry[\"population_description\"])\n",
    "    label_int = torch.Tensor(label_int)\n",
    "\n",
    "\n",
    "    # Create a Data object, add it to the list\n",
    "    new_entry = Data()\n",
    "\n",
    "    new_entry.x = node_feats\n",
    "    new_entry.edge_index = edge_idx\n",
    "    new_entry.edge_attr = edge_feats\n",
    "    new_entry.y = label_int\n",
    "\n",
    "    data_list.append(new_entry)\n",
    "\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle Successful\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./pickles/datalist.pkl', 'wb') as fp:\n",
    "    pickle.dump(data_list, fp)\n",
    "    print(\"Pickle Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle loaded\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./pickles/datalist.pkl', 'rb') as fp:\n",
    "    data_list = pickle.load(fp)\n",
    "    print(\"Pickle loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1]), Data(x=[1149, 84], edge_index=[2, 211276], edge_attr=[211276, 1], y=[1])]\n"
     ]
    }
   ],
   "source": [
    "print(data_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Neural Network Classifier #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchmetrics.classification import MulticlassAUROC\n",
    "from torch_geometric.loader import DataLoader\n",
    "from IPython.display import Javascript\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle loaded\n",
      "Pickle loaded\n"
     ]
    }
   ],
   "source": [
    "with open('./pickles/datalist.pkl', 'rb') as fp:\n",
    "    data_list = pickle.load(fp)\n",
    "    print(\"Pickle loaded\")\n",
    "\n",
    "with open('./pickles/ethset.pkl', 'rb') as fp:\n",
    "    ethnicities = pickle.load(fp)\n",
    "    print(\"Pickle loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnicity_le = LabelEncoder()\n",
    "\n",
    "ethnicity_le.fit(list(ethnicities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(data_list) * 0.8)\n",
    "\n",
    "train_list = data_list[:split]\n",
    "valid_list = data_list[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 8\n",
      "DataBatch(x=[9192, 84], edge_index=[2, 1690208], edge_attr=[1690208, 1], y=[8], batch=[9192], ptr=[9])\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 8\n",
      "DataBatch(x=[9192, 84], edge_index=[2, 1690208], edge_attr=[1690208, 1], y=[8], batch=[9192], ptr=[9])\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 8\n",
      "DataBatch(x=[9192, 84], edge_index=[2, 1690208], edge_attr=[1690208, 1], y=[8], batch=[9192], ptr=[9])\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 8\n",
      "DataBatch(x=[9192, 84], edge_index=[2, 1690208], edge_attr=[1690208, 1], y=[8], batch=[9192], ptr=[9])\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 8\n",
      "DataBatch(x=[9192, 84], edge_index=[2, 1690208], edge_attr=[1690208, 1], y=[8], batch=[9192], ptr=[9])\n",
      "Step 6:\n",
      "=======\n",
      "Number of graphs in the current batch: 8\n",
      "DataBatch(x=[9192, 84], edge_index=[2, 1690208], edge_attr=[1690208, 1], y=[8], batch=[9192], ptr=[9])\n",
      "Step 7:\n",
      "=======\n",
      "Number of graphs in the current batch: 8\n",
      "DataBatch(x=[9192, 84], edge_index=[2, 1690208], edge_attr=[1690208, 1], y=[8], batch=[9192], ptr=[9])\n",
      "Step 8:\n",
      "=======\n",
      "Number of graphs in the current batch: 8\n",
      "DataBatch(x=[9192, 84], edge_index=[2, 1690208], edge_attr=[1690208, 1], y=[8], batch=[9192], ptr=[9])\n",
      "Step 9:\n",
      "=======\n",
      "Number of graphs in the current batch: 8\n",
      "DataBatch(x=[9192, 84], edge_index=[2, 1690208], edge_attr=[1690208, 1], y=[8], batch=[9192], ptr=[9])\n",
      "Step 10:\n",
      "=======\n",
      "Number of graphs in the current batch: 8\n",
      "DataBatch(x=[9192, 84], edge_index=[2, 1690208], edge_attr=[1690208, 1], y=[8], batch=[9192], ptr=[9])\n",
      "Step 11:\n",
      "=======\n",
      "Number of graphs in the current batch: 8\n",
      "DataBatch(x=[9192, 84], edge_index=[2, 1690208], edge_attr=[1690208, 1], y=[8], batch=[9192], ptr=[9])\n",
      "Step 12:\n",
      "=======\n",
      "Number of graphs in the current batch: 4\n",
      "DataBatch(x=[4596, 84], edge_index=[2, 845104], edge_attr=[845104, 1], y=[4], batch=[4596], ptr=[5])\n"
     ]
    }
   ],
   "source": [
    "batch_size=8\n",
    "train_loader = DataLoader(train_list, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_list, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_test(model, loss_fn, loader, device):\n",
    "     \"\"\"\n",
    "     model: pytorch GNN model\n",
    "     loss_fn: loss function\n",
    "     loader: DataLoader\n",
    "     device: device eused to bind the model and tensor\n",
    "     \"\"\"\n",
    "     model.eval()\n",
    "     auroc_score = 0.0\n",
    "     ml_auroc = MulticlassAUROC(26, average='macro')\n",
    "     preds = None\n",
    "     labels = None\n",
    "\n",
    "     with torch.no_grad():\n",
    "          for data in loader:\n",
    "               out = model(data.x.to(torch.float32).to(device), data.edge_index.to(device), data.edge_attr.to(device), data.batch.to(device))\n",
    "\n",
    "               if preds is None:\n",
    "                    preds = out\n",
    "               else:\n",
    "                    preds = torch.cat((preds, out))\n",
    "\n",
    "               if labels is None:\n",
    "                    labels = data.y.to(device).long()\n",
    "               else:\n",
    "                    labels = torch.cat((labels, data.y.to(device).long()))\n",
    "     \n",
    "     print(preds.shape)\n",
    "     auroc_score = ml_auroc(preds, labels) \n",
    "     \n",
    "        \n",
    "     return auroc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN(\n",
      "  (conv1): GraphConv(84, 64)\n",
      "  (conv2): GraphConv(64, 32)\n",
      "  (conv3): GraphConv(32, 16)\n",
      "  (fc1): Linear(in_features=16, out_features=26, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from model.GraphConvNet import GNN\n",
    "\n",
    "model = GNN(84, 64, 32, 16, len(ethnicity_le.classes_)).to(device)\n",
    "print(model)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "epoch_num = 10\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([92, 26])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thats\\miniconda3\\envs\\mlb\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 26])\n",
      "Epoch: 000, Train Loss: nan, Train Auc: 0.0574, Valid Auc: 0.0449\n",
      "torch.Size([92, 26])\n",
      "torch.Size([24, 26])\n",
      "Epoch: 001, Train Loss: nan, Train Auc: 0.0575, Valid Auc: 0.0449\n",
      "torch.Size([92, 26])\n",
      "torch.Size([24, 26])\n",
      "Epoch: 002, Train Loss: nan, Train Auc: 0.0587, Valid Auc: 0.0449\n",
      "torch.Size([92, 26])\n",
      "torch.Size([24, 26])\n",
      "Epoch: 003, Train Loss: nan, Train Auc: 0.0570, Valid Auc: 0.0449\n",
      "torch.Size([92, 26])\n",
      "torch.Size([24, 26])\n",
      "Epoch: 004, Train Loss: nan, Train Auc: 0.0580, Valid Auc: 0.0449\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[39mreturn\u001b[39;00m total_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(train_loader)\n\u001b[0;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epoch_num):\n\u001b[1;32m---> 20\u001b[0m     train_loss \u001b[39m=\u001b[39m train()\n\u001b[0;32m     21\u001b[0m     train_auroc \u001b[39m=\u001b[39m graph_test(model, loss_fn, train_loader, device)\n\u001b[0;32m     22\u001b[0m     valid_auroc \u001b[39m=\u001b[39m graph_test(model, loss_fn, valid_loader, device)\n",
      "Cell \u001b[1;32mIn[22], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m      5\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m train_loader:  \u001b[39m# Iterate in batches over the training dataset.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[39m# print(data.x.dtype)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[39m# print(data.edge_index.dtype)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[39m# print(data.edge_attr.to(torch.float64).dtype)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[39m# print(data.batch.dtype)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     out \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32)\u001b[39m.\u001b[39mto(device), data\u001b[39m.\u001b[39medge_index\u001b[39m.\u001b[39mto(device), data\u001b[39m.\u001b[39medge_attr\u001b[39m.\u001b[39mto(device), data\u001b[39m.\u001b[39mbatch\u001b[39m.\u001b[39mto(device))  \u001b[39m# Perform a single forward pass.\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(out, data\u001b[39m.\u001b[39my\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mLongTensor)\u001b[39m.\u001b[39mto(device))  \u001b[39m# Compute the loss.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Thats\\miniconda3\\envs\\mlb\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Thats\\miniconda3\\envs\\mlb\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Thats\\miniconda3\\envs\\mlb\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\Thats\\miniconda3\\envs\\mlb\\lib\\site-packages\\torch_geometric\\loader\\dataloader.py:20\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     18\u001b[0m elem \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39m]\n\u001b[0;32m     19\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, BaseData):\n\u001b[1;32m---> 20\u001b[0m     \u001b[39mreturn\u001b[39;00m Batch\u001b[39m.\u001b[39;49mfrom_data_list(batch, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfollow_batch,\n\u001b[0;32m     21\u001b[0m                                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexclude_keys)\n\u001b[0;32m     22\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m     23\u001b[0m     \u001b[39mreturn\u001b[39;00m default_collate(batch)\n",
      "File \u001b[1;32mc:\\Users\\Thats\\miniconda3\\envs\\mlb\\lib\\site-packages\\torch_geometric\\data\\batch.py:76\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[1;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_data_list\u001b[39m(\u001b[39mcls\u001b[39m, data_list: List[BaseData],\n\u001b[0;32m     66\u001b[0m                    follow_batch: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     67\u001b[0m                    exclude_keys: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     68\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[39m    Python list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39m    :obj:`follow_batch`.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[39m    Will exclude any keys given in :obj:`exclude_keys`.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m     batch, slice_dict, inc_dict \u001b[39m=\u001b[39m collate(\n\u001b[0;32m     77\u001b[0m         \u001b[39mcls\u001b[39;49m,\n\u001b[0;32m     78\u001b[0m         data_list\u001b[39m=\u001b[39;49mdata_list,\n\u001b[0;32m     79\u001b[0m         increment\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     80\u001b[0m         add_batch\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(data_list[\u001b[39m0\u001b[39;49m], Batch),\n\u001b[0;32m     81\u001b[0m         follow_batch\u001b[39m=\u001b[39;49mfollow_batch,\n\u001b[0;32m     82\u001b[0m         exclude_keys\u001b[39m=\u001b[39;49mexclude_keys,\n\u001b[0;32m     83\u001b[0m     )\n\u001b[0;32m     85\u001b[0m     batch\u001b[39m.\u001b[39m_num_graphs \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data_list)\n\u001b[0;32m     86\u001b[0m     batch\u001b[39m.\u001b[39m_slice_dict \u001b[39m=\u001b[39m slice_dict\n",
      "File \u001b[1;32mc:\\Users\\Thats\\miniconda3\\envs\\mlb\\lib\\site-packages\\torch_geometric\\data\\collate.py:84\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39m# Collate attributes into a unified representation:\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m value, slices, incs \u001b[39m=\u001b[39m _collate(attr, values, data_list, stores,\n\u001b[0;32m     85\u001b[0m                                increment)\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, Tensor) \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mis_cuda:\n\u001b[0;32m     88\u001b[0m     device \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mdevice\n",
      "File \u001b[1;32mc:\\Users\\Thats\\miniconda3\\envs\\mlb\\lib\\site-packages\\torch_geometric\\data\\collate.py:135\u001b[0m, in \u001b[0;36m_collate\u001b[1;34m(key, values, data_list, stores, increment)\u001b[0m\n\u001b[0;32m    133\u001b[0m     incs \u001b[39m=\u001b[39m get_incs(key, values, data_list, stores)\n\u001b[0;32m    134\u001b[0m     \u001b[39mif\u001b[39;00m incs\u001b[39m.\u001b[39mdim() \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mint\u001b[39m(incs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 135\u001b[0m         values \u001b[39m=\u001b[39m [\n\u001b[0;32m    136\u001b[0m             value \u001b[39m+\u001b[39m inc\u001b[39m.\u001b[39mto(value\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    137\u001b[0m             \u001b[39mfor\u001b[39;00m value, inc \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(values, incs)\n\u001b[0;32m    138\u001b[0m         ]\n\u001b[0;32m    139\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    140\u001b[0m     incs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Thats\\miniconda3\\envs\\mlb\\lib\\site-packages\\torch_geometric\\data\\collate.py:135\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    133\u001b[0m     incs \u001b[39m=\u001b[39m get_incs(key, values, data_list, stores)\n\u001b[0;32m    134\u001b[0m     \u001b[39mif\u001b[39;00m incs\u001b[39m.\u001b[39mdim() \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mint\u001b[39m(incs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 135\u001b[0m         values \u001b[39m=\u001b[39m [\n\u001b[0;32m    136\u001b[0m             value \u001b[39m+\u001b[39m inc\u001b[39m.\u001b[39mto(value\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    137\u001b[0m             \u001b[39mfor\u001b[39;00m value, inc \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(values, incs)\n\u001b[0;32m    138\u001b[0m         ]\n\u001b[0;32m    139\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    140\u001b[0m     incs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        # print(data.x.dtype)\n",
    "        # print(data.edge_index.dtype)\n",
    "        # print(data.edge_attr.to(torch.float64).dtype)\n",
    "        # print(data.batch.dtype)\n",
    "        out = model(data.x.to(torch.float32).to(device), data.edge_index.to(device), data.edge_attr.to(device), data.batch.to(device))  # Perform a single forward pass.\n",
    "        loss = loss_fn(out, data.y.type(torch.LongTensor).to(device))  # Compute the loss.\n",
    "        total_loss += loss\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    train_loss = train()\n",
    "    train_auroc = graph_test(model, loss_fn, train_loader, device)\n",
    "    valid_auroc = graph_test(model, loss_fn, valid_loader, device)\n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.5f}, Train Auc: {train_auroc:.4f}, Valid Auc: {valid_auroc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
